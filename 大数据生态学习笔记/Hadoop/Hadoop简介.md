# Hadoop简介

<!-- TOC -->

- [Hadoop简介](#hadoop%e7%ae%80%e4%bb%8b)
  - [什么是大数据](#%e4%bb%80%e4%b9%88%e6%98%af%e5%a4%a7%e6%95%b0%e6%8d%ae)
  - [Hadoop是什么](#hadoop%e6%98%af%e4%bb%80%e4%b9%88)
    - [核心](#%e6%a0%b8%e5%bf%83)
  - [HDFS总结](#hdfs%e6%80%bb%e7%bb%93)
  - [HDFS概念](#hdfs%e6%a6%82%e5%bf%b5)
    - [数据块](#%e6%95%b0%e6%8d%ae%e5%9d%97)
    - [NameNode -主](#namenode--%e4%b8%bb)
    - [DataNode-从](#datanode-%e4%bb%8e)
  - [HDFS优缺点](#hdfs%e4%bc%98%e7%bc%ba%e7%82%b9)
    - [优点](#%e4%bc%98%e7%82%b9)
    - [缺点](#%e7%bc%ba%e7%82%b9)
  - [数据仓库Data Warehouse](#%e6%95%b0%e6%8d%ae%e4%bb%93%e5%ba%93data-warehouse)
  - [Google的基本思想](#google%e7%9a%84%e5%9f%ba%e6%9c%ac%e6%80%9d%e6%83%b3)
  - [Hadoop 功能和优势](#hadoop-%e5%8a%9f%e8%83%bd%e5%92%8c%e4%bc%98%e5%8a%bf)
  - [Hadoop生态系统和版本](#hadoop%e7%94%9f%e6%80%81%e7%b3%bb%e7%bb%9f%e5%92%8c%e7%89%88%e6%9c%ac)

<!-- /TOC -->


## 什么是大数据


大数据是一个概念也是一门技术，是在以**Hadoop为代表**的大数据平台框架上进行的数据分析技术

**`大数据还包括了以Hadoop和Spark为代表的基础大数据框架`**

还包括了实时数据处理，离线数据处理， 数据分析，数据挖掘和用机器算法进行预测分析技术等


## Hadoop是什么

Hadoop是一个开源的大数据框架
Hadoop是一个分布式计算的解决方案

**`Hadoop=HDFS(分布式文件系统）+MapReduce(分布式计算）`**

### 核心
**`HDFS: 存储是大数据的基础`**
**`MapReduce: 分布式计算是大数据应用的解决方案`**

## HDFS总结
普通的成百上千的机器
按TB/PB为单位的大量数据
简单便捷的文件获取

## HDFS概念

### 数据块
- 数据块是抽象块而非整个文件作为存储单元
- 默认大小为64MB, 一般设置为128M, 备份x3

### NameNode -主
- 管理文件系统的命名空间，存放文件元数据 --- 这里的元数据表示的是数据的结构
- 维护着文件系统的所有文件和目录，文件与数据块的映射
- 记录每个文件中各个块所在数据节点的信息

### DataNode-从
- 存储并检索数据块
- 向NameNode更新所存储快的列表


## HDFS优缺点

### 优点
- 适合大文件(百万规模以上的文件数量）存储，支持TB、PB级的数据存储，并有副本策略
- 可以构建在廉价的机器上，并有一定的容错和恢复机制：
数据自动保存多个副本，可以通过增加副本的形式，提高容错性
某个副本丢失以后，可以自动恢复

- 支持流式数据访问，一次写入，多次读取最高效

### 缺点
- 不适合大量小文件存储

```
原因：
1.存储大量小文件的话，会占用NameNode大量的内存来存储文件目录和块信息
这样是不可取的，因为NameNode的内存总是有限的

2.小文件存储的寻址时间会超过读取时间，违反了HDFS的设计目标

-不适合并发写入，不支持文件随机修改
1.一个文件只能有一个写，不允许多个线程同时写
2.仅支持数据append（追加），不支持文件的随机修改
```
- 不支持随机读等低延迟的访问方式： 比如毫秒级别的存储数据做不到



## 数据仓库Data Warehouse


##  Google的基本思想

Google 大数据技术 ： MapReduce, BigTable, GFS
革命性技术

1）成本降低，能用PC机， 就不用大型机和高端存储
2）软件容错硬件故障视为常态，通过软件保证可靠性
3）简化并行分布式计算，无须控制节点同步和数据交换

## Hadoop 功能和优势
开源、分布式存储、分布式计算
包含两核心组成：
1）HDFS: 分布式文件系统，存储海量的数据
2）MapReduce: 并行处理框架，实现任务分解和调度

用途：
搭建大型数据仓库，PB级数据的存储，处理，分析，统计等业务

优势：
1）高扩展
2）低成本
3）成熟的生态圈


## Hadoop生态系统和版本

Hive : Sql->Hadoop任务
Hbase: 存储结构化、数据的分布式数据库
区别HDFS:  提供数据随机读写和实现对表数据的读写功能

Zookeeper:   稳定V1.2版本







